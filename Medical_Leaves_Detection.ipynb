{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.8.17","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":6417582,"sourceType":"datasetVersion","datasetId":3701557},{"sourceId":6675703,"sourceType":"datasetVersion","datasetId":3851533}],"dockerImageVersionId":30559,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2023-11-03T06:42:19.592225Z","iopub.execute_input":"2023-11-03T06:42:19.592520Z","iopub.status.idle":"2023-11-03T06:42:59.794452Z","shell.execute_reply.started":"2023-11-03T06:42:19.592489Z","shell.execute_reply":"2023-11-03T06:42:59.793611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install \"numpy>=1.16.5,<1.23.0\"","metadata":{"execution":{"iopub.status.busy":"2023-11-03T06:42:59.795803Z","iopub.execute_input":"2023-11-03T06:42:59.796254Z","iopub.status.idle":"2023-11-03T06:43:09.271737Z","shell.execute_reply.started":"2023-11-03T06:42:59.796226Z","shell.execute_reply":"2023-11-03T06:43:09.270598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Convert Images in directory into Dataset\nwe can use `tf.keras.preprocessing.image_dataset_from_directory` to convert the data into dataset so we can train the models out of the box","metadata":{}},{"cell_type":"code","source":"dataset = tf.keras.preprocessing.image_dataset_from_directory(\n    \"/kaggle/input/indian-medicinal-leaves-dataset/Indian Medicinal Leaves Image Datasets/Medicinal Leaf dataset\",\n    shuffle=True,\n    batch_size=32,\n    image_size=(299, 299),\n)\n\nlabels = dataset.class_names\nlabels","metadata":{"execution":{"iopub.status.busy":"2023-11-03T06:43:09.272978Z","iopub.execute_input":"2023-11-03T06:43:09.273252Z","iopub.status.idle":"2023-11-03T06:43:13.751660Z","shell.execute_reply.started":"2023-11-03T06:43:09.273226Z","shell.execute_reply":"2023-11-03T06:43:13.750877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\nfor image_batch, labels_batch in dataset.take(1):\n    print(image_batch.shape)\n    print(labels_batch.numpy())\n    break","metadata":{"execution":{"iopub.status.busy":"2023-11-03T06:43:13.753374Z","iopub.execute_input":"2023-11-03T06:43:13.753622Z","iopub.status.idle":"2023-11-03T06:43:15.064071Z","shell.execute_reply.started":"2023-11-03T06:43:13.753600Z","shell.execute_reply":"2023-11-03T06:43:15.063104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train test split\ntrain_size = int(0.8 * len(dataset))\ntest_size = int(0.2 * len(dataset))\ntrain_size, test_size","metadata":{"execution":{"iopub.status.busy":"2023-11-03T06:43:15.065040Z","iopub.execute_input":"2023-11-03T06:43:15.065291Z","iopub.status.idle":"2023-11-03T06:43:15.071763Z","shell.execute_reply.started":"2023-11-03T06:43:15.065269Z","shell.execute_reply":"2023-11-03T06:43:15.071005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train, Test, Validate\npartition the data into train test and validation datasets","metadata":{}},{"cell_type":"code","source":"def get_dataset_partitions_tf(ds, train_split=0.8, test_split=0.2, shuffle=True, shuffle_size=10000):\n    if shuffle:\n        ds = ds.shuffle(shuffle_size, seed=12)\n    train_size = int(train_split * len(ds))\n    test_size = int(test_split * len(ds))\n    train_ds = ds.take(train_size)\n    test_ds = ds.skip(train_size)\n    val_ds = test_ds.skip(test_size)\n    test_ds = test_ds.take(test_size)\n    return train_ds, test_ds, val_ds","metadata":{"execution":{"iopub.status.busy":"2023-11-03T06:43:15.072592Z","iopub.execute_input":"2023-11-03T06:43:15.072847Z","iopub.status.idle":"2023-11-03T06:43:15.083085Z","shell.execute_reply.started":"2023-11-03T06:43:15.072811Z","shell.execute_reply":"2023-11-03T06:43:15.082422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds, test_ds, val_ds = get_dataset_partisions_tf(dataset)\nlen(train_ds), len(test_ds), len(val_ds)","metadata":{"execution":{"iopub.status.busy":"2023-11-03T06:43:15.083882Z","iopub.execute_input":"2023-11-03T06:43:15.084117Z","iopub.status.idle":"2023-11-03T06:43:15.100150Z","shell.execute_reply.started":"2023-11-03T06:43:15.084098Z","shell.execute_reply":"2023-11-03T06:43:15.099425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Resize and Normalize\n- Iception models takes the image input as 299x299 pixels so converting into the trainable format is necessary\n- The Images are to be normalized before to train accurately and efficiently","metadata":{}},{"cell_type":"code","source":"resize_and_rescale = tf.keras.Sequential([\n    tf.keras.layers.experimental.preprocessing.Resizing(299, 299),\n    tf.keras.layers.experimental.preprocessing.Rescaling(1./255)\n])\nprint(\"Done\")","metadata":{"execution":{"iopub.status.busy":"2023-11-03T06:43:15.100939Z","iopub.execute_input":"2023-11-03T06:43:15.101177Z","iopub.status.idle":"2023-11-03T06:43:15.114680Z","shell.execute_reply.started":"2023-11-03T06:43:15.101157Z","shell.execute_reply":"2023-11-03T06:43:15.113990Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Download the Xception model predefined weights from tensorflow into your working environment","metadata":{}},{"cell_type":"code","source":"# train using Iception\nbase_model = tf.keras.applications.InceptionV3(\n    weights='imagenet',\n    input_shape=(299, 299, 3),\n    include_top=False,\n    pooling='avg',\n    classifier_activation='softmax',\n    classes=len(labels)\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-03T06:43:15.115444Z","iopub.execute_input":"2023-11-03T06:43:15.115663Z","iopub.status.idle":"2023-11-03T06:43:18.405705Z","shell.execute_reply.started":"2023-11-03T06:43:15.115643Z","shell.execute_reply":"2023-11-03T06:43:18.404827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model.trainable = False\n\ninputs = tf.keras.Input(shape=(299, 299, 3))\nx = resize_and_rescale(inputs)\nx = base_model(x, training=False)\nx = tf.keras.layers.Dense(128, activation='relu')(x)\nx = tf.keras.layers.Dropout(0.2)(x)\noutputs = tf.keras.layers.Dense(len(labels), activation='softmax')(x)\nmodel = tf.keras.Model(inputs, outputs)\n\nmodel.compile(\n    optimizer='adam',\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nmodel.summary()\n\nhistory = model.fit(\n    train_ds,\n    validation_data=val_ds,\n    batch_size=32,\n    epochs=20\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-03T06:43:18.408325Z","iopub.execute_input":"2023-11-03T06:43:18.408608Z","iopub.status.idle":"2023-11-03T07:15:58.692668Z","shell.execute_reply.started":"2023-11-03T06:43:18.408583Z","shell.execute_reply":"2023-11-03T07:15:58.691678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(test_ds)","metadata":{"execution":{"iopub.status.busy":"2023-11-03T07:15:58.694008Z","iopub.execute_input":"2023-11-03T07:15:58.694275Z","iopub.status.idle":"2023-11-03T07:16:28.619215Z","shell.execute_reply.started":"2023-11-03T07:15:58.694251Z","shell.execute_reply":"2023-11-03T07:16:28.618232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predict with new images\nimport numpy as np\n\nimg = tf.keras.preprocessing.image.load_img(\n    '/kaggle/input/test-medicinal-leaves/alo.jpg', target_size=(299, 299)\n)\nimg_array = tf.keras.preprocessing.image.img_to_array(img)\nimg_array = tf.expand_dims(img_array, 0)  # Create a batch\n\n\npredictions = model.predict(img_array)\nscore = tf.nn.sigmoid(predictions[0])\nprint(\n    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n    .format(labels[np.argmax(score)], 100 * np.max(score))\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-03T07:16:28.620387Z","iopub.execute_input":"2023-11-03T07:16:28.620671Z","iopub.status.idle":"2023-11-03T07:16:29.431681Z","shell.execute_reply.started":"2023-11-03T07:16:28.620647Z","shell.execute_reply":"2023-11-03T07:16:29.430386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predict with new images\nimport numpy as np\n\nimg = tf.keras.preprocessing.image.load_img(\n    '/kaggle/input/test-medicinal-leaves/bamboo.jpeg', target_size=(299, 299)\n)\nimg_array = tf.keras.preprocessing.image.img_to_array(img)\nimg_array = tf.expand_dims(img_array, 0)  # Create a batch\npredictions = model.predict(img_array)\nscore = tf.nn.sigmoid(predictions[0])\nprint(\n    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n    .format(labels[np.argmax(score)], 100 * np.max(score))\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-03T07:16:29.432411Z","iopub.status.idle":"2023-11-03T07:16:29.432718Z","shell.execute_reply.started":"2023-11-03T07:16:29.432563Z","shell.execute_reply":"2023-11-03T07:16:29.432577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\nimg = tf.keras.preprocessing.image.load_img(\n    '/kaggle/input/test-medicinal-leaves/betel-leaf-1024x1024.jpg', target_size=(299, 299)\n)\nimg_array = tf.keras.preprocessing.image.img_to_array(img)\nimg_array = tf.expand_dims(img_array, 0)  # Create a batch\npredictions = model.predict(img_array)\nscore = tf.nn.sigmoid(predictions[0])\nprint(\n    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n    .format(labels[np.argmax(score)], 100 * np.max(score))\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-03T07:16:29.434005Z","iopub.status.idle":"2023-11-03T07:16:29.434299Z","shell.execute_reply.started":"2023-11-03T07:16:29.434153Z","shell.execute_reply":"2023-11-03T07:16:29.434167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\nimg = tf.keras.preprocessing.image.load_img(\n    '/kaggle/input/test-medicinal-leaves/bamboo.jpeg', target_size=(299, 299)\n)\nimg_array = tf.keras.preprocessing.image.img_to_array(img)\nimg_array = tf.expand_dims(img_array, 0)  # Create a batch\npredictions = model.predict(img_array)\nscore = tf.nn.sigmoid(predictions[0])\nprint(\n    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n    .format(labels[np.argmax(score)], 100 * np.max(score))\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-03T07:16:29.435236Z","iopub.status.idle":"2023-11-03T07:16:29.435519Z","shell.execute_reply.started":"2023-11-03T07:16:29.435378Z","shell.execute_reply":"2023-11-03T07:16:29.435392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\nimg = tf.keras.preprocessing.image.load_img(\n    '/kaggle/input/test-medicinal-leaves/doddapatre.jpg', target_size=(299, 299)\n)\nimg_array = tf.keras.preprocessing.image.img_to_array(img)\nimg_array = tf.expand_dims(img_array, 0)  # Create a batch\npredictions = model.predict(img_array)\nscore = tf.nn.sigmoid(predictions[0])\nprint(\n    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n    .format(labels[np.argmax(score)], 100 * np.max(score))\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-03T07:16:29.436836Z","iopub.status.idle":"2023-11-03T07:16:29.437143Z","shell.execute_reply.started":"2023-11-03T07:16:29.436997Z","shell.execute_reply":"2023-11-03T07:16:29.437012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\nimg = tf.keras.preprocessing.image.load_img(\n    '/kaggle/input/test-medicinal-leaves/tulsi-leaves-t-cut-500x500.jpg.webp', target_size=(299, 299)\n)\nimg_array = tf.keras.preprocessing.image.img_to_array(img)\nimg_array = tf.expand_dims(img_array, 0)  # Create a batch\npredictions = model.predict(img_array)\nscore = tf.nn.sigmoid(predictions[0])\nprint(\n    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n    .format(labels[np.argmax(score)], 100 * np.max(score))\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-03T07:16:29.438155Z","iopub.status.idle":"2023-11-03T07:16:29.438477Z","shell.execute_reply.started":"2023-11-03T07:16:29.438316Z","shell.execute_reply":"2023-11-03T07:16:29.438332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot accuracy and loss\nimport matplotlib.pyplot as plt\n\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\n\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-03T07:16:29.439462Z","iopub.status.idle":"2023-11-03T07:16:29.439749Z","shell.execute_reply.started":"2023-11-03T07:16:29.439601Z","shell.execute_reply":"2023-11-03T07:16:29.439615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('model_avg_20_inception.h5')","metadata":{"execution":{"iopub.status.busy":"2023-11-03T07:17:01.318139Z","iopub.execute_input":"2023-11-03T07:17:01.318499Z","iopub.status.idle":"2023-11-03T07:17:01.814682Z","shell.execute_reply.started":"2023-11-03T07:17:01.318474Z","shell.execute_reply":"2023-11-03T07:17:01.813807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}